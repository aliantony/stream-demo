spring:
  application:
    name: demo-consumer-application
  cloud:
    # Spring Cloud Stream 配置项，对应 BindingServiceProperties 类
    stream:
      # Binder 配置项，对应 BinderProperties Map
      #      binders:
      # Binding 配置项，对应 BindingProperties Map
      bindings:
        input-channel:
          destination: my_output1 # 目的地。这里使用 Kafka Topic
          content-type: application/json # 内容格式。这里使用 JSON
          group: my-consumer-group # 消费者分组，不指定则随机的命名消费者分组，实现广播消费
          # Consumer 配置项，对应 ConsumerProperties 类
          consumer:
            max-attempts: 3 # 重试次数，默认为 3 次（包括第一次正常消费）。1禁用重试
            back-off-initial-interval: 3000 # 重试间隔的初始值，单位毫秒，默认为 1000
            back-off-multiplier: 2.0 # 重试间隔的递乘系数，默认为 2.0
            back-off-max-interval: 10000 # 重试间隔的最大值，单位毫秒，默认为 10000
            concurrency: 2 # 每个 Consumer 消费线程数的初始大小，默认为 1，消费者创建两个线程平摊分区
            batch-mode: true # 是否批量消费默认，默认为 false
      # Spring Cloud Stream Kafka 配置项
      kafka:
        # Kafka Binder 配置项，对应 KafkaBinderConfigurationProperties 类
        binder:
          brokers: 192.168.5.102:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
          configuration:
            fetch.max.wait.ms: 10000 # poll 一次拉取的阻塞的最大时长，单位：毫秒。这里指的是阻塞拉取需要满足至少 fetch-min-size 大小的消息
            fetch.min.bytes: 1024 # poll 一次消息拉取的最小数据量，单位：字节
            max.poll.records: 100 # poll 一次消息拉取的最大数量
        bindings:
          input-channel:
            # Kafka Consumer 配置项，对应 KafkaConsumerProperties 类
            consumer:
              enable-dlq: true # 是否开启死信队列，默认为 false 关闭
              dlq-name: # 死信队列名，默认为 `errors.{topicName}.{consumerGroup}`
              auto-commit-offset: false # 是否自动提交消费进度，默认为 true 自动提交。
              ack-each-record: true # 是否每一条消息都进行提交消费进度，默认为 false 在每一批消费完成后一起提交。
              configuration:
                isolation:
                  level: read_committed # 读取已提交的消息

server:
  port: ${random.int[10000,19999]} # 随机端口，方便启动多个消费者